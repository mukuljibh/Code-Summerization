{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c5H2TA4KUtv5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mukul\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RFoYhntjUtv6"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "default_dropout=0.2\n",
        "batch_size = 48\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IAjKtQw3Utv6"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your CSV file\n",
        "csv_file_path = 'train.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "input=df[\"output\"].tolist()\n",
        "output=df[\"instruction\"].tolist()\n",
        "\n",
        "words_to_remove=[\"Write\",\"Rewrite\",\"a\",\"Create\",\"Generate\",\"Implement\",\"an\",\"In\",\"Craft\",\"Construct\"]\n",
        "code_to=[\"\\n\",\"\\t\",\"#\",\"{\",\"}\"]\n",
        "\n",
        "# Function to remove specified words from a sentence\n",
        "def remove_words(sentence, words):\n",
        "    return ' '.join([w for w in sentence.split() if w not in words])\n",
        "\n",
        "# Preprocess the data to remove the words\n",
        "preprocessed_data_summary = [remove_words(sentence, words_to_remove) for sentence in output]\n",
        "preprocessed_data_code=[remove_words(sentence, code_to) for sentence in input]\n",
        "a=[]\n",
        "b=[]\n",
        "for i in range(0,len(preprocessed_data_summary)):\n",
        "    if(len(preprocessed_data_code[i])<500 and len(preprocessed_data_summary[i])<500):\n",
        "        a.append(preprocessed_data_code[i])\n",
        "        b.append(preprocessed_data_summary[i])\n",
        "preprocessed_data_code=a\n",
        "preprocessed_data_summary=b\n",
        "code_summarry=pd.DataFrame(preprocessed_data_summary, columns=['instruction'])\n",
        "code_snippet=pd.DataFrame(preprocessed_data_code, columns=['output'])\n",
        "input_train=code_snippet[\"output\"]\n",
        "input_test=code_snippet[\"output\"].head(2)\n",
        "output_train=code_summarry[\"instruction\"]\n",
        "output_test=code_summarry[\"instruction\"].head(2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15449"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HicImGPUUtv7"
      },
      "outputs": [],
      "source": [
        "def generate_decoder_inputs_targets(sentences, tokenizer):\n",
        "  seqs = tokenizer.texts_to_sequences(sentences)\n",
        "  decoder_inputs = [s[:-1] for s in seqs] # Drop the last token in the sentence.\n",
        "  decoder_targets = [s[1:] for s in seqs] # Drop the first token in the sentence.\n",
        "\n",
        "  return decoder_inputs, decoder_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6uUgs5z7Utv7"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = [f\"{input_train[i]}<sep>{output_train[i]}\" for i in range(len(a))]\n",
        "\n",
        "\n",
        "SEPARATOR = '<sep>'\n",
        "train_input, train_target = map(list, zip(*[pair.split(SEPARATOR) for pair in train]))\n",
        "\n",
        "def normalize_unicode(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(s):\n",
        "  s = normalize_unicode(s)\n",
        "  s = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = s.strip()\n",
        "  return s\n",
        "\n",
        "train_preprocessed_input = [preprocess_sentence(s) for s in train_input]\n",
        "train_preprocessed_target = [preprocess_sentence(s) for s in train_target]\n",
        "\n",
        "def tag_target_sentences(sentences):\n",
        "  tagged_sentences = map(lambda s: (' ').join(['<sos>', s, '<eos>']), sentences)\n",
        "  return list(tagged_sentences)\n",
        "\n",
        "train_tagged_preprocessed_target = tag_target_sentences(train_preprocessed_target)\n",
        "\n",
        "\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$&;@^_`{|}~\\t\\n')\n",
        "source_tokenizer.fit_on_texts(train_preprocessed_input)\n",
        "source_tokenizer.get_config()\n",
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\".#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
        "target_tokenizer.fit_on_texts(train_tagged_preprocessed_target)\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "train_encoder_inputs = source_tokenizer.texts_to_sequences(train_preprocessed_input)\n",
        "train_decoder_inputs, train_decoder_targets = generate_decoder_inputs_targets(train_tagged_preprocessed_target,target_tokenizer)\n",
        "\n",
        "\n",
        "max_encoding_len = len(max(train_encoder_inputs, key=len))\n",
        "max_decoding_len = len(max(train_decoder_inputs, key=len))\n",
        "\n",
        "\n",
        "\n",
        "padded_train_encoder_inputs = pad_sequences(train_encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
        "padded_train_decoder_inputs = pad_sequences(train_decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
        "padded_train_decoder_targets = pad_sequences(train_decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "val = [f\"{input_test[i]}<sep>{output_test[i]}\" for i in range(0,2)]\n",
        "\n",
        "\n",
        "def process_dataset(dataset):\n",
        "\n",
        "  # Split the Hungarian and English sentences into separate lists.\n",
        "  input, output = map(list, zip(*[pair.split(SEPARATOR) for pair in dataset]))\n",
        "\n",
        "  # Unicode normalization and inserting spaces around punctuation.\n",
        "  preprocessed_input = [preprocess_sentence(s) for s in input]\n",
        "  preprocessed_output = [preprocess_sentence(s) for s in output]\n",
        "\n",
        "  # Tag target sentences with <sos> and <eos> tokens.\n",
        "  tagged_preprocessed_output = tag_target_sentences(preprocessed_output)\n",
        "\n",
        "  # Vectorize encoder source sentences.\n",
        "  encoder_inputs = source_tokenizer.texts_to_sequences(preprocessed_input)\n",
        "\n",
        "  # Vectorize and create decoder input and target sentences.\n",
        "  decoder_inputs, decoder_targets = generate_decoder_inputs_targets(tagged_preprocessed_output,\n",
        "                                                                    target_tokenizer)\n",
        "\n",
        "  # Pad all collections.\n",
        "  padded_encoder_inputs = pad_sequences(encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
        "  padded_decoder_inputs = pad_sequences(decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
        "  padded_decoder_targets = pad_sequences(decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
        "\n",
        "  return padded_encoder_inputs, padded_decoder_inputs, padded_decoder_targets\n",
        "\n",
        "padded_val_encoder_inputs, padded_val_decoder_inputs, padded_val_decoder_targets = process_dataset(val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jzpZrj92E5Dc",
        "outputId": "76ab4d03-9886-47e6-b6c1-e96b51f04f06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "max_encoding_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93bSaYZXE5Dc",
        "outputId": "b6c7962a-47c9-461b-8764-d3048443c7be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_decoding_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d0S-p25XRWR",
        "outputId": "6dec5624-8db1-44cd-8276-6b4b181f67b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15449"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "q_TRC2DcUtv7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mukul\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The initial encoder input layer which will take in padded sequences. We're specifying\n",
        "# a shape of None here but you can specify it upfront if you want since we\n",
        "# know what the max encoding length is.\n",
        "encoder_inputs = layers.Input(shape=[None], name='encoder_inputs')\n",
        "\n",
        "# The embedding layer. Similar to what we did in the RNN demo.\n",
        "encoder_embeddings = layers.Embedding(source_vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      mask_zero=True,\n",
        "                                      name='encoder_embeddings')\n",
        "\n",
        "# Passing the input layer output to the embedding layer creates a link between the\n",
        "# two. Input sequences will now flow into the embedding layer which will output\n",
        "# a sequence of embeddings.\n",
        "encoder_embedding_output = encoder_embeddings(encoder_inputs)\n",
        "\n",
        "\n",
        "# We're not using any kind of attention mechanism in this model, so setting only\n",
        "# return_state to True is enough. return_sequences remains False.\n",
        "encoder_lstm = layers.LSTM(hidden_dim,\n",
        "                           return_state=True,\n",
        "                           dropout=default_dropout,\n",
        "                           name='encoder_lstm')\n",
        "\n",
        "# Passing the embedding layer output to the LSTM layer creates another link.\n",
        "# IMPORTANT: The LSTM always returns three values. When return_sequences is\n",
        "# False, encoder_outputs and state_h are the SAME. When return_sequences is\n",
        "# True, encoder_outputs contains the encoder hidden states from each time step.\n",
        "#\n",
        "# Side note: we won't be using encoder_outputs here so that variable can be\n",
        "# replaced with a _ if preferred.\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding_output)\n",
        "\n",
        "# The final hidden and cell/context states from the encoder will be the the\n",
        "# initial states for the decoder.\n",
        "encoder_states = (state_h, state_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xq3L7p_lUtv7"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = layers.Input(shape=[None], name='decoder_inputs')\n",
        "\n",
        "\n",
        "decoder_embeddings = layers.Embedding(target_vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      mask_zero=True,\n",
        "                                      name='decoder_embeddings')\n",
        "\n",
        "\n",
        "decoder_embedding_output = decoder_embeddings(decoder_inputs)\n",
        "\n",
        "# Return sequences set to True.\n",
        "decoder_lstm = layers.LSTM(hidden_dim,\n",
        "                           return_sequences=True,\n",
        "                           return_state=True,\n",
        "                           dropout=default_dropout,\n",
        "                           name='decoder_lstm')\n",
        "\n",
        "\n",
        "# Set the decoder's initial state to the encoder's final output states. Since\n",
        "# return_sequences is set to True, decoder_outputs is going to be a collection of\n",
        "# the decoder's hidden state at each timestep. Also note that since we don't need\n",
        "# the decoder's final hidden output and cell states, those are just set to _.\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding_output, initial_state=encoder_states)\n",
        "\n",
        "# Have a softmax layer in the end to create a probability distribution for the output word.\n",
        "decoder_dense = layers.Dense(target_vocab_size, activation='softmax', name='decoder_dense')\n",
        "\n",
        "# The probability distribution for the output word.\n",
        "y_proba = decoder_dense(decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfmYKW4PUtv7",
        "outputId": "e3659aca-5c98-4350-f733-d3a5849ec704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mukul\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"hun_eng_seq2seq_nmt_no_attention\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_embeddings (Embedd  (None, None, 128)            1115724   ['encoder_inputs[0][0]']      \n",
            " ing)                                                     8                                       \n",
            "                                                                                                  \n",
            " decoder_embeddings (Embedd  (None, None, 128)            903552    ['decoder_inputs[0][0]']      \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)         [(None, 256),                394240    ['encoder_embeddings[0][0]']  \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, None, 256),          394240    ['decoder_embeddings[0][0]',  \n",
            "                              (None, 256),                           'encoder_lstm[0][1]',        \n",
            "                              (None, 256)]                           'encoder_lstm[0][2]']        \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)       (None, None, 7059)           1814163   ['decoder_lstm[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14663443 (55.94 MB)\n",
            "Trainable params: 14663443 (55.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Note how the model is taking two inputs in an array.\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], y_proba, name='hun_eng_seq2seq_nmt_no_attention')\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',  metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "788JdKo7Utv8"
      },
      "outputs": [],
      "source": [
        "filepath = \"cp.weights.h5\"\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ren5A5EKUtv8",
        "outputId": "ce0d2287-bd92-4c14-be46-c5a401c2ffa1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2f2cbaecf4a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mes_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit([padded_train_encoder_inputs, padded_train_decoder_inputs], padded_train_decoder_targets,\n\u001b[1;32m      4\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit([padded_train_encoder_inputs, padded_train_decoder_inputs], padded_train_decoder_targets,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=([padded_val_encoder_inputs, padded_val_decoder_inputs], padded_val_decoder_targets),\n",
        "                      callbacks=[cp_callback, es_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b2ZUBEeOUtv8",
        "outputId": "a37728a9-a1b3-4b5b-f5d1-a3a76fc2f4b2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-05ffaa10750a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m###### Save the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hun_eng_s2s_nmt_no_attention.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m###### Save the tokenizers as JSON files. The resulting files can be downloaded by left-clicking on them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msource_tokenizer_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "###### Save the model.\n",
        "model.save('hun_eng_s2s_nmt_no_attention.keras')\n",
        "\n",
        "###### Save the tokenizers as JSON files. The resulting files can be downloaded by left-clicking on them.\n",
        "source_tokenizer_json = source_tokenizer.to_json()\n",
        "with io.open('source_tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "   f.write(json.dumps(source_tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "target_tokenizer_json = target_tokenizer.to_json()\n",
        "with io.open('target_tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "   f.write(json.dumps(target_tokenizer_json, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HAYVKupE5Dd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5Di4z_plE5Dd"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # No masking here. We'll handle it ourselves.\n",
        "        self.embedding = layers.Embedding(source_vocab_size,\n",
        "                                          embedding_dim,\n",
        "                                          name='encoder_embedding_layer')\n",
        "\n",
        "        # return_sequences is set to True this time.\n",
        "        self.lstm = layers.LSTM(hidden_dim,\n",
        "                                return_sequences=True,\n",
        "                                return_state=True,\n",
        "                                name='encoder_lstm')\n",
        "\n",
        "    def call(self, input):\n",
        "        embeddings = self.embedding(input)\n",
        "\n",
        "        # output_seq will hold the encoder's hidden states from each time step.\n",
        "        output_seq, state_h, state_c = self.lstm(embeddings)\n",
        "\n",
        "        return output_seq, state_h, state_c\n",
        "test_encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)\n",
        "test_encoder_batch = padded_train_encoder_inputs[:3]\n",
        "\n",
        "test_encoder_outputs, state_h, state_c = test_encoder(test_encoder_batch)\n",
        "# Sample encoder LSTM output for single sequence of length 4.\n",
        "encoder_out = tf.constant([[1., 2., 3.],\n",
        "                           [2., 3., 4.],\n",
        "                           [3., 4., 5.],\n",
        "                           [4., 5. ,6.]])\n",
        "# Sample decoder LSTM output for a single timestep.\n",
        "decoder_out = tf.constant([[1., 3., 5.]])\n",
        "\n",
        "tf.transpose(encoder_out)\n",
        "attention_scores = tf.matmul(decoder_out, encoder_out, transpose_b=True)\n",
        "\n",
        "attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
        "context = tf.matmul(attention_weights, encoder_out)\n",
        "class LuongAttention(tf.keras.Model):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(LuongAttention, self).__init__()\n",
        "\n",
        "    self.w = layers.Dense(hidden_dim, name='encoder_outputs_dense')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    encoder_output_seq, decoder_output = inputs\n",
        "    z = self.w(encoder_output_seq)\n",
        "    attention_scores = tf.matmul(decoder_output, z, transpose_b=True)\n",
        "    attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
        "    context = tf.matmul(attention_weights, encoder_output_seq)\n",
        "\n",
        "    return attention_weights, context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JV_JPNnbE5De"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.embedding_layer = layers.Embedding(vocab_size,\n",
        "                                            embedding_dim,\n",
        "                                            name='decoder_embedding_layer')\n",
        "\n",
        "    self.lstm = layers.LSTM(hidden_dim,\n",
        "                            return_sequences=True,\n",
        "                            return_state=True,\n",
        "                            name='decoder_lstm')\n",
        "\n",
        "    self.attention = LuongAttention(hidden_dim)\n",
        "\n",
        "    self.w = tf.keras.layers.Dense(hidden_dim, activation='tanh', name='attended_outputs_dense')\n",
        "\n",
        "    self.dense = layers.Dense(vocab_size, name='decoder_dense')\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    decoder_input, encoder_output_seq, lstm_state = inputs\n",
        "    embeddings = self.embedding_layer(decoder_input)\n",
        "\n",
        "    decoder_output, state_h, state_c = self.lstm(embeddings, initial_state=lstm_state)\n",
        "\n",
        "    weights, context = self.attention([encoder_output_seq, decoder_output])\n",
        "\n",
        "    decoder_output_with_attention = self.w(tf.concat(\n",
        "        [tf.squeeze(context, 1), tf.squeeze(decoder_output, 1)], -1))\n",
        "\n",
        "    logits = self.dense(decoder_output_with_attention)\n",
        "\n",
        "    return logits, state_h, state_c, weights\n",
        "test_decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gslR9xgjE5De"
      },
      "outputs": [],
      "source": [
        "test_decoder_batch = padded_train_decoder_inputs[:3]\n",
        "next_decoder_inputs = tf.expand_dims(test_decoder_batch[:, 1], 1)\n",
        "test_decoder_logits, state_h, state_c, test_decoder_weights = test_decoder(\n",
        "    [\n",
        "      next_decoder_inputs,\n",
        "      test_encoder_outputs,\n",
        "      [state_h, state_c]\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IRMnPFdTE5De"
      },
      "outputs": [],
      "source": [
        "def loss_func(targets, logits):\n",
        "  ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
        "\n",
        "  return ce_loss(targets, logits, sample_weight=mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VV8sjw_uE5De"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((padded_train_encoder_inputs,\n",
        "                                              padded_train_decoder_inputs,\n",
        "                                              padded_train_decoder_targets)).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4L9mi9hzE5De"
      },
      "outputs": [],
      "source": [
        "class TranslatorTrainer(tf.keras.Model):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(TranslatorTrainer, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  # This method will be called by model.fit for each batch.\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      loss = 0.\n",
        "\n",
        "      encoder_input_seq, decoder_input_seq, decoder_target_seq = inputs\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          encoder_output_seq, state_h, state_c = self.encoder(encoder_input_seq)\n",
        "\n",
        "          # We need to create a loop to iterate through the target sequences\n",
        "          for i in range(decoder_target_seq.shape[1]):\n",
        "\n",
        "              # Input to the decoder must have shape of (batch_size, length)\n",
        "              # so we need to expand one dimension (just like in the previous example).\n",
        "              next_decoder_input = tf.expand_dims(decoder_input_seq[:, i], 1)\n",
        "              logits, state_h, state_c, _ = self.decoder(\n",
        "                  [next_decoder_input, encoder_output_seq, (state_h, state_c)])\n",
        "\n",
        "              # The loss is now accumulated through the whole batch\n",
        "              loss += self.loss(decoder_target_seq[:, i], logits)\n",
        "\n",
        "      # Update the parameters and the optimizer\n",
        "      variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "      self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "      return {'loss': loss / decoder_target_seq.shape[1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "iGgRu0olE5De"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)\n",
        "decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "translator_trainer = TranslatorTrainer(encoder, decoder)\n",
        "translator_trainer.compile(optimizer=optimizer, loss=loss_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29JuqC_8E5De",
        "outputId": "fc08700d-4165-4314-c3b8-8b0f3f10f641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "321/321 [==============================] - 535s 1s/step - loss: 0.8964\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 453s 1s/step - loss: 0.6959\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 455s 1s/step - loss: 0.5811\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 459s 1s/step - loss: 0.5212\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 462s 1s/step - loss: 0.4781\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 471s 1s/step - loss: 0.4522\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 458s 1s/step - loss: 0.4236\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 540s 2s/step - loss: 0.3966\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 500s 2s/step - loss: 0.3741\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 477s 1s/step - loss: 0.3544\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 479s 1s/step - loss: 0.3370\n",
            "Epoch 12/50\n",
            "321/321 [==============================] - 494s 2s/step - loss: 0.3215\n",
            "Epoch 13/50\n",
            "321/321 [==============================] - 833s 3s/step - loss: 0.3068\n",
            "Epoch 14/50\n",
            "321/321 [==============================] - 1295s 4s/step - loss: 0.2932\n",
            "Epoch 15/50\n",
            "321/321 [==============================] - 439s 1s/step - loss: 0.2800\n",
            "Epoch 16/50\n",
            "321/321 [==============================] - 458s 1s/step - loss: 0.2661\n",
            "Epoch 17/50\n",
            "321/321 [==============================] - 460s 1s/step - loss: 0.2530\n",
            "Epoch 18/50\n",
            "321/321 [==============================] - 459s 1s/step - loss: 0.2404\n",
            "Epoch 19/50\n",
            "321/321 [==============================] - 782s 2s/step - loss: 0.2284\n",
            "Epoch 20/50\n",
            "321/321 [==============================] - 450s 1s/step - loss: 0.2175\n",
            "Epoch 21/50\n",
            "321/321 [==============================] - 463s 1s/step - loss: 0.2072\n",
            "Epoch 22/50\n",
            "321/321 [==============================] - 1672s 5s/step - loss: 0.1970\n",
            "Epoch 23/50\n",
            "321/321 [==============================] - 453s 1s/step - loss: 0.1878\n",
            "Epoch 24/50\n",
            "321/321 [==============================] - 450s 1s/step - loss: 0.1787\n",
            "Epoch 25/50\n",
            "321/321 [==============================] - 448s 1s/step - loss: 0.1685\n",
            "Epoch 26/50\n",
            "321/321 [==============================] - 446s 1s/step - loss: 0.1585\n",
            "Epoch 27/50\n",
            "321/321 [==============================] - 448s 1s/step - loss: 0.1502\n",
            "Epoch 28/50\n",
            "321/321 [==============================] - 450s 1s/step - loss: 0.1411\n",
            "Epoch 29/50\n",
            "321/321 [==============================] - 448s 1s/step - loss: 0.1324\n",
            "Epoch 30/50\n",
            "321/321 [==============================] - 534s 2s/step - loss: 0.1234\n",
            "Epoch 31/50\n",
            "321/321 [==============================] - 36260s 113s/step - loss: 0.1150\n",
            "Epoch 32/50\n",
            "321/321 [==============================] - 433s 1s/step - loss: 0.1072\n",
            "Epoch 33/50\n",
            "321/321 [==============================] - 446s 1s/step - loss: 0.1011\n",
            "Epoch 34/50\n",
            "321/321 [==============================] - 459s 1s/step - loss: 0.0958\n",
            "Epoch 35/50\n",
            "321/321 [==============================] - 458s 1s/step - loss: 0.0888\n",
            "Epoch 36/50\n",
            "321/321 [==============================] - 751s 2s/step - loss: 0.0841\n",
            "Epoch 37/50\n",
            "321/321 [==============================] - 765s 2s/step - loss: 0.0779\n",
            "Epoch 38/50\n",
            "321/321 [==============================] - 798s 2s/step - loss: 0.0725\n",
            "Epoch 39/50\n",
            "321/321 [==============================] - 750s 2s/step - loss: 0.0679\n",
            "Epoch 40/50\n",
            "321/321 [==============================] - 751s 2s/step - loss: 0.0637\n",
            "Epoch 41/50\n",
            "321/321 [==============================] - 483s 2s/step - loss: 0.0588\n",
            "Epoch 42/50\n",
            "321/321 [==============================] - 676s 2s/step - loss: 0.0546\n",
            "Epoch 43/50\n",
            "321/321 [==============================] - 480s 1s/step - loss: 0.0520\n",
            "Epoch 44/50\n",
            "321/321 [==============================] - 467s 1s/step - loss: 0.0499\n",
            "Epoch 45/50\n",
            "321/321 [==============================] - 471s 1s/step - loss: 0.0473\n",
            "Epoch 46/50\n",
            "321/321 [==============================] - 457s 1s/step - loss: 0.0438\n",
            "Epoch 47/50\n",
            "321/321 [==============================] - 460s 1s/step - loss: 0.0410\n",
            "Epoch 48/50\n",
            "321/321 [==============================] - 459s 1s/step - loss: 0.0384\n",
            "Epoch 49/50\n",
            "321/321 [==============================] - 678s 2s/step - loss: 0.0357\n",
            "Epoch 50/50\n",
            "321/321 [==============================] - 726s 2s/step - loss: 0.0353\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x28274f78f10>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 50\n",
        "translator_trainer.fit(dataset, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuLZEXhhE5De",
        "outputId": "215652ec-9cff-4488-9765-49de107633bd"
      },
      "outputs": [],
      "source": [
        "encoder.save_weights('encoder.TF')\n",
        "decoder.save_weights('decoder.weights.TF')\n",
        "\n",
        "# !zip -r ./attention_weights.zip ./attention_weights\n",
        "\n",
        "# files.download('./attention_weights.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mukul\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:538: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2827cfb7a90>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "encoder.load_weights('encoder.TF')\n",
        "decoder.load_weights('decoder.weights.TF')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "uTRSi5_pNTqF"
      },
      "outputs": [],
      "source": [
        "def translate_with_attention(sentence: str,\n",
        "                             source_tokenizer, encoder,\n",
        "                             target_tokenizer, decoder,\n",
        "                             max_translated_len = 30):\n",
        "    input_seq = source_tokenizer.texts_to_sequences([sentence])\n",
        "    tokenized = source_tokenizer.sequences_to_texts(input_seq)\n",
        "\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_encoding_len, padding='post')\n",
        "    encoder_output, state_h, state_c  = encoder.predict(input_seq)\n",
        "\n",
        "    current_word = '<sos>'\n",
        "    decoded_sentence = []\n",
        "\n",
        "    while len(decoded_sentence) < max_translated_len:\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = target_tokenizer.word_index[current_word]\n",
        "\n",
        "        logits, state_h, state_c, _ = decoder.predict([target_seq, encoder_output, (state_h, state_c)])\n",
        "        current_token_index = np.argmax(logits[0])\n",
        "\n",
        "        current_word = target_tokenizer.index_word[current_token_index]\n",
        "\n",
        "        if (current_word == '<eos>'):\n",
        "          break\n",
        "\n",
        "        decoded_sentence.append(current_word)\n",
        "\n",
        "    return tokenized[0], ' '.join(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "emtxHcjlNeDT"
      },
      "outputs": [],
      "source": [
        "def translate_sentences(sentences, translation_func, source_tokenizer, encoder,\n",
        "                        target_tokenizer, decoder):\n",
        "  translations = {'Tokenized Original': [], 'Reference': [], 'Translation': []}\n",
        "\n",
        "  for s in sentences:\n",
        "    source, target = s.split(SEPARATOR)\n",
        "    source = preprocess_sentence(source)\n",
        "    tokenized_sentence, translated = translation_func(source, source_tokenizer, encoder,\n",
        "                                                      target_tokenizer, decoder)\n",
        "\n",
        "    translations['Tokenized Original'].append(tokenized_sentence)\n",
        "    translations['Reference'].append(target)\n",
        "    translations['Translation'].append(translated)\n",
        "\n",
        "  return translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5xrjCSnE5De",
        "outputId": "83998bd2-5409-4e35-b053-27ea5740fbdd"
      },
      "outputs": [],
      "source": [
        "train[300:301]\n",
        "sentences=train[300:301]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmEbVnDfE5De",
        "outputId": "4f74d8cc-a2e2-46b8-9b66-95284320e99e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "shorter_translations_w_attention = pd.DataFrame(translate_sentences(sentences, translate_with_attention,\n",
        "                                                                    source_tokenizer, encoder,\n",
        "                                                                    target_tokenizer, decoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "MBZ8oAtJNzSF",
        "outputId": "3bcdf2bb-ed3f-4d64-8337-92831702ac31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenized Original</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Translation W/ Attention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>def find substring(source , substring): '''thi...</td>\n",
              "      <td>Python program to find substring in string.</td>\n",
              "      <td>python program to find substring in string</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Tokenized Original  \\\n",
              "0  def find substring(source , substring): '''thi...   \n",
              "\n",
              "                                     Reference  \\\n",
              "0  Python program to find substring in string.   \n",
              "\n",
              "                     Translation W/ Attention  \n",
              "0  python program to find substring in string  "
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shorter_translations_w_attention.rename(columns={'Translation': 'Translation W/ Attention'}, inplace=True)\n",
        "shorter_translations_w_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tXR5v-kE5De",
        "outputId": "6ad2f678-aa0f-431c-89de-f1c8eaff6ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Python program to find substring in string.'],\n",
              " ['python program to find substring in string'])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shorter_translations_w_attention[\"Reference\"].tolist(),shorter_translations_w_attention[\"Translation W/ Attention\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBkzjWP_E5De"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwVrr45xE5De"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
